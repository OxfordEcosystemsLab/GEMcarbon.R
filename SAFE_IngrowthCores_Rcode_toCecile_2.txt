# Code written by Terhi Riutta, 2015.
# Fit four alternative saturating functions to the IC data.

setwd("C:/Users/triutta/Dropbox/SAFE_Terhi")
getwd()

data_all<-read.table("SAFE_IngrowthCores_data_toR.txt", header=T, )
names(data_all)
dim(data_all)

# Units for the roots are g biomass per core over the collection interval
# Values are cumulative biomass from the start of the search

# Exclude missing values
data<-na.exclude(data_all)
names(data)
dim(data)

# A new dataframe for root production only
data.NPP<-data[data$DataType=="NPP",]
names(data.NPP)
dim(data.NPP)
# Remember to drop the empty factor levels!
data.NPP<-droplevels(data.NPP)

# Convert root NPP to g biomass month-1 (divide by the number of days between collections and multiply by 30)
Coarse<-data.NPP$CoarseRoot.cum/data.NPP$DaysBetween*30
Fine<-data.NPP$FineRoot.cum/data.NPP$DaysBetween*30
Total<-data.NPP$TotRoot.cum/data.NPP$DaysBetween*30

data.NPP<-cbind(data.NPP, Coarse, Fine, Total)
dim(data.NPP)
NAcheck<-complete.cases(data.NPP)
# --> no missing values


# For modelling, should we use only fine root mass, or include the 'coarse' roots?
# Let's assume that the coarse roots are fine enough

# # # # # # # # # # # # # # 


library(nlme)

# Fit four alternative saturating functions to the data
# Michaelis-Mente, Exponential rise, Power, Logarithmic. See GEM manual for details
# Combined code identifies the data belonning to the same core at the same date


# Michaelis-Menten model
# a*TIME/(b+TIME)

model1<-nlsList(Total~b1*Search.time.cum/(b2+Search.time.cum)|Combined.code.2,
data=data.NPP, 
start=list(b1=1,b2=7),
control=list(maxiter=5000,minFactor=0.0000001))

summary(model1)

b1<-coef(model1)[1]
b2<-coef(model1)[2]


# Exponential rise to maximum model

model2<-nlsList(Total~b3*(1-exp(-b4*Search.time.cum))|Combined.code.2,
data=data.NPP, 
start=list(b3=1,b4=0.08),
control=list(maxiter=5000,minFactor=0.0000001))
summary(model2)

b3<-coef(model2)[1]
b4<-coef(model2)[2]


# Power model
model3<-nlsList(Total~b5*Search.time.cum^b6 |Combined.code.2,
data=data.NPP, 
start=list(b5=1,b6=0.2),
control=list(maxiter=5000,minFactor=0.0000001))
summary(model3)

b5<-coef(model3)[1]
b6<-coef(model3)[2]

# Logarithmic model

model4<-nlsList(Total~b7+b8*log(Search.time.cum) |Combined.code.2,
data=data.NPP, 
start=list(b7=0,b8=0.07),
control=list(maxiter=5000,minFactor=0.0000001))
summary(model4)

b7<-coef(model4)[1]
b8<-coef(model4)[2]


# Look for the maximum value (root mass at the end of the search) for each core 
# If none of the curves converged, use this as the estimate of the root mass

max<-tapply(data.NPP$Total,data.NPP$Combined.code.2,max)


# Create a dataframe that combines the parameters of the four alternative models and max root biomass

parameters<-data.frame(b1,b2,b3,b4,b5,b6,b7,b8,max)
Combined.code.2<-rownames(parameters)
rownames(parameters)=NULL
parameters<-cbind(Combined.code.2, parameters)
names(parameters)


# Solve the four equations to 120 mins
# We assume that after searching 120 mins we would have been able to extract all the roots
# So this represent the total root mass in the core
# Chris has used 100 mins and power law, but best to stick to the same method as Khoon (120 mins and log-curve as the default)

Maxtime<-120 #120 mins as the max search time

# Each equation solved to 120 mins (--> total root mass in the core)
MichaelisMenten<-b1*Maxtime/(b2+Maxtime)
ExponentialRise<-b3*(1-exp(-b4*Maxtime))
Power<-b5*Maxtime^b6
Logarithmic<-b7+b8*log(Maxtime)

# A quick and dirty comparison of how the estimates vary between the equations
colMeans(Logarithmic, na.rm=T)
colMeans(ExpoenntialRise, na.rm=T)
colMeans(MichaelisMenten, na.rm=T)
colMeans(Power, na.rm=T)




# Total root NPP, assuming that all roots are extracted in 120 mins ('Search time corrected root NPP')
# Create a data frame that combines the model parameters and the results from the four models (at 120 mins)

Root.SCorr<-cbind(parameters, MichaelisMenten, ExponentialRise, Power, Logarithmic)
names(Root.SCorr)<-c("Combined.code.2", "b1", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "max", "MichaelisMenten", "ExponentialRise", "Power", "Logarithmic") 
names(Root.SCorr)



# Let's assume Logarithmi is the best model, 
# If that does not converge, then Michaelis-Mente
# If that does not converge. then Power
# If that does not converge, then ExponentialRis
# If none of the curves converge, then used the total cumulative value from the raw data (max)
Tot.SCorr<-ifelse(!is.na(Root.SCorr$Logarithmic), Root.SCorr$Logarithmic, 
	ifelse(!is.na(Root.SCorr$MichaelisMenten), Root.SCorr$MichaelisMenten, 
	ifelse(!is.na(Root.SCorr$Power), Root.SCorr$Power, 
	ifelse(!is.na(Root.SCorr$ExponentialRise), Root.SCorr$ExponentialRise, Root.SCorr$max))))

length(Tot.SCorr)



# The end result is one value per core per retrieval day, the total mass of 'fine' roots in the core
# The units are still g biomass per core per month





# # # # # # # # # # # # #

# Correct for the uneven core retrieval frequency
# If data not collected every 90 days, some of the data should be given more weight to the annual estimates
# This is not necessary in all sites 
	
# Copy the days between variable to

DaysBetween<-tapply(data.NPP$DaysBetween, data.NPP$Combined.code.2, mean)
length(DaysBetween)

Root.SCorr2<-data.frame(Root.SCorr$Combined.code.2, Tot.SCorr, DaysBetween)
names(Root.SCorr2)<-c("Combined.code.2", "Tot.SCorr", "DaysBetween")
names(Root.SCorr2)


# Convert the combined code back into plot, Core and day

Comb.code.2.char<-as.character(Root.SCorr2$Combined.code.2)

SplitCode<-strsplit(Comb.code.2.char, "\\.")

CodeMatrix<-matrix(unlist(SplitCode), ncol=3, byrow=TRUE)
dim(CodeMatrix)
names(CodeMatrix)

Plot<-as.factor(CodeMatrix[,1])
levels(Plot)

Date<-as.vector(CodeMatrix[,2])

Core<-as.factor(CodeMatrix[,3])
levels(Core)

PlotCore<-as.factor(paste(Plot, Core))
levels(PlotCore)

# Combine into one dataframe

Root.SCorr3<-cbind(Root.SCorr2, Plot, Date, Core, PlotCore)
names(Root.SCorr3)


# Calculate Tot root mass weighed by the number of days

Tot.SCorr.w<-Root.SCorr3$Tot.SCorr*Root.SCorr3$DaysBetween

sums.Tot.SCorr.w<-aggregate(cbind(Tot.SCorr.w, Root.SCorr3$DaysBetween)~Root.SCorr3$Plot+Root.SCorr3$Core, FUN=sum)
dim(sums.Tot.SCorr.w)
names(sums.Tot.SCorr.w)<-c("Plot", "Core", "sums.Tot.SCorr.w", "sums.DaysBetween")
names(sums.Tot.SCorr.w)

Tot.SCorr.mean<-sums.Tot.SCorr.w$sums.Tot.SCorr/sums.Tot.SCorr.w$sums.DaysBetween
length(Tot.SCorr.mean)

# Then end results is temporal average per core (by plots), corrected for the uneven collection frequency
# unit is g biomass per core



# # # # # # #

# Depth profile of roots. Estimate how much below the 30 cm in-growth core depth
# Calculate to 1 m
# Use same correction factor as Khoon

DepthCorr.Khoon.Yoda<-1.125
# From Yoda 1983, used by Khoon


Tot.SCorr.mean.depth<-Tot.Scorr.mean*DepthCorr.Khoon.Yoda


# This is the old depth equation from Chris's code (check source), but better to use the same one as Khoon

# RootDepth = 0.5*(exp(-7.344*depth)+exp(-1.303*depth))
# Depth unit is metres

# Integral from 0.3 to 1 m

# RootDepth<-function(x) {0.5*(exp(-7.344*x)+exp(-1.303*x))}
# RootBelow30.Proportion<-integrate(RootDepth, lower=0.3, upper=1)
# RootBelow30.Proportion.numeric<-as.numeric(RootBelow30.Proportion[1])
# RootBelow30.Proportion.numeric

# 16.28% of the roots is below 30 cm zone

# Calculate depth corrected root mass
# Tot.SCorr.mean.depth<-Tot.SCorr.mean*(1+RootBelow30.Proportion.numeric)



# # # # # # # # # 

# Unit conversion from g biomass per core per month
# to Mg C ha-1 year-1


# Core dimensions (m)
d<-0.12
h<-0.30

A<-(d/2)^2*pi

# Carbon content
cc<-0.5


# Divided by A --> per m2
# Multiplied by 10000 --> per ha
# Multiplied by 12 --> per year
# Divided by 10^6 --> from g to Mg
# Multiplied by carbon content --> From biomass to carbon

Tot.Corrected.MgCha<-Tot.SCorr.mean.depth/A*10000*12/(10^6)*cc
length(Tot.Corrected.MgCha)

# new dataframe
IC.ByCore<-data.frame(sums.Tot.SCorr.w$Plot,sums.Tot.SCorr.w$Core,Tot.Corrected.MgCha)
names(IC.ByCore)<-c("Plot", "Core", "Tot.Roots.MgChayr") 
dim(IC.ByCore)

write.table(IC.ByCore, "SAFE_IC_fromR_byCore.txt", row.names=F)


# # # # # # # # # 

# Calculate plot means from the corrected (search time, temporal frequency, depth), unit converted (Mg C ha-1 yr-1) data

PlotMeans<-aggregate(IC.ByCore$Tot.Roots.MgChayr~IC.ByCore$Plot, FUN=mean)
names(PlotMeans)


# Write a function for calculating standard error
s.e<-function(x) {sd(x)/sqrt(length(x))}


PlotSE<-aggregate(IC.ByCore$Tot.Roots.MgChayr~IC.ByCore$Plot, FUN=s.e)
names(PlotSE)

# Into one dataframe

IC.PlotMeans.SE<-data.frame(PlotMeans[,1:2], PlotSE[,2])
names(IC.PlotMeans.SE)<-c("Plot", "Mean", "SE")


write.table(IC.PlotMeans.SE, "SAFE_IC_fromR2.txt", row.names=F)









